<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" /><title>Configuring machine learning
        | Elastic Stack Overview [master]
      | Elastic
    </title><link rel="home" href="index.html" title="Elastic Stack Overview [master]" /><link rel="up" href="ml-configuration.html" title="Configuring anomaly detection" /><link rel="prev" href="ml-configuration.html" title="Configuring anomaly detection" /><link rel="next" href="create-jobs.html" title="Creating anomaly detection jobs" /><meta name="DC.type" content="Learn/Docs/Elastic Stack/Overview/master" /><meta name="DC.subject" content="Elastic Stack" /><meta name="DC.identifier" content="master" />
    <meta http-equiv="content-type" content="text/html; charset=utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="apple-touch-icon" sizes="57x57" href="/apple-icon-57x57.png">
    <link rel="apple-touch-icon" sizes="60x60" href="/apple-icon-60x60.png">
    <link rel="apple-touch-icon" sizes="72x72" href="/apple-icon-72x72.png">
    <link rel="apple-touch-icon" sizes="76x76" href="/apple-icon-76x76.png">
    <link rel="apple-touch-icon" sizes="114x114" href="/apple-icon-114x114.png">
    <link rel="apple-touch-icon" sizes="120x120" href="/apple-icon-120x120.png">
    <link rel="apple-touch-icon" sizes="144x144" href="/apple-icon-144x144.png">
    <link rel="apple-touch-icon" sizes="152x152" href="/apple-icon-152x152.png">
    <link rel="apple-touch-icon" sizes="180x180" href="/apple-icon-180x180.png">
    <link rel="icon" type="image/png" href="/favicon-32x32.png" sizes="32x32">
    <link rel="icon" type="image/png" href="/android-chrome-192x192.png" sizes="192x192">
    <link rel="icon" type="image/png" href="/favicon-96x96.png" sizes="96x96">
    <link rel="icon" type="image/png" href="/favicon-16x16.png" sizes="16x16">
    <link rel="manifest" href="/manifest.json">
    <link rel="mask-icon" href="/safari-pinned-tab.svg" color="#ffffff">
    <meta name="apple-mobile-web-app-title" content="Elastic">
    <meta name="application-name" content="Elastic">
    <meta name="msapplication-TileColor" content="#ffffff">
    <meta name="msapplication-TileImage" content="/mstile-144x144.png">
    <meta name="theme-color" content="#ffffff">
    <meta name="naver-site-verification" content="936882c1853b701b3cef3721758d80535413dbfd" />
    <meta name="yandex-verification" content="d8a47e95d0972434" />
    <meta name="localized" content="true" />
    <meta property="og:image" content="https://www.elastic.co/static/images/elastic-logo-200.png" />
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/favicon.ico" type="image/x-icon">
    <link rel="apple-touch-icon-precomposed" sizes="64x64" href="/favicon_64x64_16bit.png">
    <link rel="apple-touch-icon-precomposed" sizes="32x32" href="/favicon_32x32.png">
    <link rel="apple-touch-icon-precomposed" sizes="16x16" href="/favicon_16x16.png">
    <script src="/static/js/jquery.min.js"></script>
    <!-- Give IE8 a fighting chance -->
    <!--[if lt IE 9]>
    <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
    <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
    <link rel="stylesheet" type="text/css" href="/guide/static/styles.css" />
  </head>

  <body>
    <!-- Google Tag Manager -->
    <script>dataLayer = [];</script><noscript><iframe src="//www.googletagmanager.com/ns.html?id=GTM-58RLH5" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
    <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start': new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0], j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src= '//www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f); })(window,document,'script','dataLayer','GTM-58RLH5');</script>
    <!-- End Google Tag Manager -->
    
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-12395217-16"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-12395217-16');
    </script>

    <div id='elastic-nav' style="display:none;"></div>
    <script src='https://www.elastic.co/elastic-nav.js'></script>

    <!-- Subnav -->
    <div>
      <div>
        <div class="tertiary-nav d-none d-md-block">
          <div class="container">
            <div class="p-t-b-15 d-flex justify-content-between nav-container">
              <div class="breadcrum-wrapper"><span><a href="/guide/" style="font-size: 14px; font-weight: 600; color: #000;">Docs</a></span></div>
            </div>
          </div>
        </div>
      </div>
    </div>

    <div class="main-container">
      <section id="content" >
        <div class="content-wrapper">

          <section id="guide" lang="en">
            <div class="container">
              <div class="row">
                <div class="col-xs-12 col-sm-8 col-md-8 guide-section">
                  <!-- start body -->
                  <div class="page_header">You are looking at preliminary documentation for a future release.
Not what you want? See the
<a href="../current/index.html">current release documentation</a>.
</div><div class="breadcrumbs"><span class="breadcrumb-link"><a href="index.html">Elastic Stack Overview
      [master]
    </a></span> » <span class="breadcrumb-link"><a href="xpack-ml.html">Machine learning anomaly detection</a></span> » <span class="breadcrumb-link"><a href="ml-configuration.html">Configuring anomaly detection</a></span> » <span class="breadcrumb-node">Configuring machine learning</span></div><div class="navheader"><span class="prev"><a href="ml-configuration.html">
              « 
              Configuring anomaly detection</a>
           
        </span><span class="next">
           
          <a href="create-jobs.html">Creating anomaly detection jobs
               »
            </a></span></div><div class="xpack section"><div class="titlepage"><div><div><h2 class="title"><a id="ml-configuring"></a>Configuring machine learning<a href="https://github.com/elastic/elasticsearch/edit/master/docs/reference/ml/anomaly-detection/configuring.asciidoc" class="edit_me" title="Edit this page on GitHub" rel="nofollow">edit</a><a class="xpack_tag" href="/subscriptions"></a></h2></div></div></div><p>If you want to use machine learning features, there must be at least one machine learning node in
your cluster and all master-eligible nodes must have machine learning enabled. By default,
all nodes are machine learning nodes. For more information about these settings, see
<a class="ulink" href="https://www.elastic.co/guide/en/elasticsearch/reference/master/modules-node.html#ml-node" target="_top">machine learning nodes</a>.</p><p>To use the machine learning features to analyze your data, you can create an anomaly detection job
and send your data to that job.</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">If your data is stored in Elasticsearch:</p><div class="itemizedlist"><ul class="itemizedlist" type="circle"><li class="listitem">You can create a datafeed, which retrieves data from Elasticsearch for analysis.</li><li class="listitem">You can use Kibana to expedite the creation of jobs and datafeeds.</li></ul></div></li><li class="listitem">If your data is not stored in Elasticsearch, you can
<a class="ulink" href="https://www.elastic.co/guide/en/elasticsearch/reference/master/ml-post-data.html" target="_top">POST data</a> from any source directly to an API.</li></ul></div><p>The results of machine learning analysis are stored in Elasticsearch and you can use Kibana to help
you visualize and explore the results.</p><p>Though it is quite simple to analyze your data and provide quick machine learning results,
gaining deep insights might require some additional planning and configuration.
The scenarios in this section describe some best practices for generating useful
machine learning results and insights from your data.</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><a class="xref" href="ml-configuring.html#ml-configuring-url" title="Adding custom URLs to machine learning results">Adding custom URLs to machine learning results</a></li><li class="listitem"><a class="xref" href="ml-configuring.html#ml-configuring-aggregation" title="Aggregating data for faster performance">Aggregating data for faster performance</a></li><li class="listitem"><a class="xref" href="ml-configuring.html#ml-configuring-categories" title="Categorizing log messages">Categorizing log messages</a></li><li class="listitem"><a class="xref" href="ml-configuring.html#ml-configuring-detector-custom-rules" title="Customizing detectors with custom rules">Customizing detectors with custom rules</a></li><li class="listitem"><a class="xref" href="ml-configuring.html#ml-configuring-pop" title="Performing population analysis">Performing population analysis</a></li><li class="listitem"><a class="xref" href="ml-configuring.html#ml-configuring-transform" title="Transforming data with script fields">Transforming data with script fields</a></li><li class="listitem"><a class="xref" href="ml-configuring.html#ml-delayed-data-detection" title="Handling delayed data">Handling delayed data</a></li></ul></div><div class="xpack section"><div class="titlepage"><div><div><h3 class="title"><a id="ml-configuring-url"></a>Adding custom URLs to machine learning results<a href="https://github.com/elastic/elasticsearch/edit/master/docs/reference/ml/anomaly-detection/customurl.asciidoc" class="edit_me" title="Edit this page on GitHub" rel="nofollow">edit</a><a class="xpack_tag" href="/subscriptions"></a></h3></div></div></div><p>When you create an advanced anomaly detection job or edit any anomaly detection jobs in Kibana,
you can optionally attach one or more custom URLs.</p><p>The custom URLs provide links from the anomalies table in the <span class="strong strong"><strong>Anomaly Explorer</strong></span>
or <span class="strong strong"><strong>Single Metric Viewer</strong></span> window in Kibana to Kibana dashboards, the <span class="strong strong"><strong>Discovery</strong></span>
page, or external websites. For example, you can define a custom URL that
provides a way for users to drill down to the source data from the results set.</p><p>When you edit an anomaly detection job in Kibana, it simplifies the creation of the
custom URLs for Kibana dashboards and the <span class="strong strong"><strong>Discover</strong></span> page and it enables you to
test your URLs. For example:</p><div class="screenshot informalfigure"><div class="mediaobject"><img src="images/ml-customurl-edit.jpg" alt="Edit a job to add a custom URL" /></div></div><p>For each custom URL, you must supply the URL and a label, which is the link text
that appears in the anomalies table. You can also optionally supply a time
range. For example, these are the values that are added for <code class="literal">My link 1</code>:</p><div class="screenshot informalfigure"><div class="mediaobject"><img src="images/ml-customurl-detail.jpg" alt="An example of a label and URL" /></div></div><p>As in this case, the custom URL can contain
<a class="link" href="ml-configuring.html#ml-configuring-url-strings" title="String substitution in custom URLs">dollar sign delimited tokens</a>, which
are populated when you click the link in the anomalies table. In this example,
the custom URL contains <code class="literal">$earliest$</code>, <code class="literal">$latest$</code>, and <code class="literal">$service$</code> tokens, which
pass the beginning and end of the time span of the selected anomaly and the
pertinent <code class="literal">service</code> field value to the target page. If you were interested in
the following anomaly, for example:</p><div class="screenshot informalfigure"><div class="mediaobject"><img src="images/ml-customurl.jpg" alt="An example of the custom URL links in the Anomaly Explorer anomalies table" /></div></div><p>…​clicking <code class="literal">My Link 1</code> opens the <span class="strong strong"><strong>Discover</strong></span> page and shows results for the
service and date that were identified in the anomaly:</p><div class="screenshot informalfigure"><div class="mediaobject"><img src="images/ml-customurl-discover.jpg" alt="An example of the results on the Discover page" /></div></div><p>Since we specified a time range of 2 hours, the time filter restricts the
results to the time period two hours before and after the anomaly.</p><p>You can also specify these custom URL settings when you create or update
anomaly detection jobs by using the APIs.</p><h5><a id="ml-configuring-url-strings"></a>String substitution in custom URLs<a href="https://github.com/elastic/elasticsearch/edit/master/docs/reference/ml/anomaly-detection/customurl.asciidoc" class="edit_me" title="Edit this page on GitHub" rel="nofollow">edit</a></h5><p>You can use dollar sign ($) delimited tokens in a custom URL. These tokens are
substituted for the values of the corresponding fields in the anomaly records.
For example, for a configured URL of
<code class="literal">http://my.datastore.com/dashboards?user=$user_name$</code>, the value of the
<code class="literal">user_name</code> field in the anomaly record is substituted into the <code class="literal">$user_name$</code>
token when you click the link in the anomalies table.</p><div class="note admon"><div class="icon"><img alt="Note" src="images/icons/note.png" /></div><div class="admon_content"><p>Not all fields in your source data exist in the anomaly results. If a
field is specified in the detector as the <code class="literal">field_name</code>, <code class="literal">by_field_name</code>,
<code class="literal">over_field_name</code>, or <code class="literal">partition_field_name</code>, for example, it can be used in a
custom URL. A field that is only used in the <code class="literal">categorization_field_name</code>
property, however, does not exist in the anomaly results.</p></div></div><p>The following keywords can also be used as tokens for string substitution in a
custom URL: <code class="literal">$earliest$</code>; <code class="literal">$latest$</code>; <code class="literal">$mlcategoryregex$</code>; <code class="literal">$mlcategoryterms$</code>.</p><p>The <code class="literal">$earliest$</code> and <code class="literal">$latest$</code> tokens pass the beginning and end of the time
span of the selected anomaly to the target page. The tokens are substituted with
date-time strings in ISO-8601 format. If you selected an interval of 1 hour for
the anomalies table, these tokens use one hour on either side of the anomaly
time as the earliest and latest times. The same is also true if the interval is
set to <code class="literal">Auto</code> and a one hour interval was chosen. You can override this behavior
by using the <code class="literal">time_range</code> setting.</p><p>The <code class="literal">$mlcategoryregex$</code> and <code class="literal">$mlcategoryterms$</code> tokens pertain to anomaly detection jobs
where you are categorizing field values. For more information about this type of
analysis, see <a class="xref" href="ml-configuring.html#ml-configuring-categories" title="Categorizing log messages">Categorizing log messages</a>.</p><p>The <code class="literal">$mlcategoryregex$</code> token passes the regular expression value of the
category of the selected anomaly, as identified by the value of the <code class="literal">mlcategory</code>
field of the anomaly record.</p><p>The <code class="literal">$mlcategoryterms$</code> token likewise passes the terms value of the category of
the selected anomaly. Each categorization term is prefixed by a plus (+)
character, so that when the token is passed to a Kibana dashboard, the resulting
dashboard query seeks a match for all of the terms of the category.</p><p>For example, the following API updates a job to add a custom URL that uses
<code class="literal">$earliest$</code>, <code class="literal">$latest$</code>, and <code class="literal">$mlcategoryterms$</code> tokens:</p><div class="pre_wrapper lang-console"><pre class="programlisting prettyprint lang-console">POST _ml/anomaly_detectors/sample_job/_update
{
  "custom_settings": {
        "custom_urls": [
          {
            "url_name": "test-link1",
            "time_range": "1h",
            "url_value": "http://localhost:5601/app/kibana#/discover?_g=(refreshInterval:(display:Off,pause:!f,value:0),time:(from:'$earliest$',mode:quick,to:'$latest$'))&amp;_a=(columns:!(_source),index:AV3OWB68ue3Ht69t29aw,interval:auto,query:(query_string:(analyze_wildcard:!t,query:'$mlcategoryterms$')),sort:!(time,desc))"
          }
        ]
      }
}</pre></div><div class="console_widget" data-snippet="snippets/75.console"></div><p>When you click this custom URL in the anomalies table in Kibana, it opens up the
<span class="strong strong"><strong>Discover</strong></span> page and displays source data for the period one hour before and
after the anomaly occurred. Since this job was categorizing log messages, some
<code class="literal">$mlcategoryterms$</code> token values that were passed to the target page for an
example anomaly are as follows:</p><div class="screenshot informalfigure"><div class="mediaobject"><img src="images/ml-categoryterms.jpg" alt="A query for category terms on the Discover page in Kibana" /></div></div><div class="tip admon"><div class="icon"><img alt="Tip" src="images/icons/tip.png" /></div><div class="admon_content"><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">The custom URL links in the anomaly tables use pop-ups. You must configure
your web browser so that it does not block pop-up windows or create an exception
for your Kibana URL.</li><li class="listitem">When creating a link to a Kibana dashboard, the URLs for dashboards can be very
long. Be careful of typos, end of line characters, and URL encoding. Also ensure
you use the appropriate index ID for the target Kibana index pattern.</li><li class="listitem">If you use an influencer name for string substitution, keep in mind that it
might not always be available in the analysis results and the URL is invalid in
those cases. There is not always a statistically significant influencer for each
anomaly.</li><li class="listitem">The dates substituted for <code class="literal">$earliest$</code> and <code class="literal">$latest$</code> tokens are in
ISO-8601 format and the target system must understand this format.</li><li class="listitem">If the job performs an analysis against nested JSON fields, the tokens for
string substitution can refer to these fields using dot notation. For example,
<code class="literal">$cpu.total$</code>.</li><li class="listitem">Elasticsearch source data mappings might make it difficult for the query string to work.
Test the custom URL before saving the job configuration to check that it works
as expected, particularly when using string substitution.</li></ul></div></div></div></div><div class="xpack section"><div class="titlepage"><div><div><h3 class="title"><a id="ml-configuring-aggregation"></a>Aggregating data for faster performance<a href="https://github.com/elastic/elasticsearch/edit/master/docs/reference/ml/anomaly-detection/aggregations.asciidoc" class="edit_me" title="Edit this page on GitHub" rel="nofollow">edit</a><a class="xpack_tag" href="/subscriptions"></a></h3></div></div></div><p>By default, datafeeds fetch data from Elasticsearch using search and scroll requests.
It can be significantly more efficient, however, to aggregate data in Elasticsearch
and to configure your anomaly detection jobs to analyze aggregated data.</p><p>One of the benefits of aggregating data this way is that Elasticsearch automatically
distributes these calculations across your cluster. You can then feed this
aggregated data into the machine learning features instead of raw results, which
reduces the volume of data that must be considered while detecting anomalies.</p><p>There are some limitations to using aggregations in datafeeds, however.
Your aggregation must include a <code class="literal">date_histogram</code> aggregation, which in turn must
contain a <code class="literal">max</code> aggregation on the time field. This requirement ensures that the
aggregated data is a time series and the timestamp of each bucket is the time
of the last record in the bucket. If you use a terms aggregation and the
cardinality of a term is high, then the aggregation might not be effective and
you might want to just use the default search and scroll behavior.</p><p>When you create or update an anomaly detection job, you can include the names of
aggregations, for example:</p><div class="pre_wrapper lang-console"><pre class="programlisting prettyprint lang-console">PUT _ml/anomaly_detectors/farequote
{
  "analysis_config": {
    "bucket_span": "60m",
    "detectors": [{
      "function": "mean",
      "field_name": "responsetime",
      "by_field_name": "airline"
    }],
    "summary_count_field_name": "doc_count"
  },
  "data_description": {
    "time_field":"time"
  }
}</pre></div><div class="console_widget" data-snippet="snippets/76.console"></div><p>In this example, the <code class="literal">airline</code>, <code class="literal">responsetime</code>, and <code class="literal">time</code> fields are
aggregations.</p><div class="note admon"><div class="icon"><img alt="Note" src="images/icons/note.png" /></div><div class="admon_content"><p>When the <code class="literal">summary_count_field_name</code> property is set to a non-null value,
the job expects to receive aggregated input. The property must be set to the
name of the field that contains the count of raw data points that have been
aggregated. It applies to all detectors in the job.</p></div></div><p>The aggregations are defined in the datafeed as follows:</p><div class="pre_wrapper lang-console"><pre class="programlisting prettyprint lang-console">PUT _ml/datafeeds/datafeed-farequote
{
  "job_id":"farequote",
  "indices": ["farequote"],
  "aggregations": {
    "buckets": {
      "date_histogram": {
        "field": "time",
        "fixed_interval": "360s",
        "time_zone": "UTC"
      },
      "aggregations": {
        "time": {
          "max": {"field": "time"}
        },
        "airline": {
          "terms": {
            "field": "airline",
            "size": 100
          },
          "aggregations": {
            "responsetime": {
              "avg": {
                "field": "responsetime"
              }
            }
          }
        }
      }
    }
  }
}</pre></div><div class="console_widget" data-snippet="snippets/77.console"></div><p>In this example, the aggregations have names that match the fields that they
operate on. That is to say, the <code class="literal">max</code> aggregation is named <code class="literal">time</code> and its
field is also <code class="literal">time</code>. The same is true for the aggregations with the names
<code class="literal">airline</code> and <code class="literal">responsetime</code>. Since you must create the job before you can
create the datafeed, synchronizing your aggregation and field names can simplify
these configuration steps.</p><div class="important admon"><div class="icon"><img alt="Important" src="images/icons/important.png" /></div><div class="admon_content"><p>If you use a <code class="literal">max</code> aggregation on a time field, the aggregation name
in the datafeed must match the name of the time field, as in the previous example.
For all other aggregations, if the aggregation name doesn’t match the field name,
there are limitations in the drill-down functionality within the machine learning page in
Kibana.</p></div></div><p>Datafeeds support complex nested aggregations, this example uses the <code class="literal">derivative</code>
pipeline aggregation to find the first order derivative of the counter
<code class="literal">system.network.out.bytes</code> for each value of the field <code class="literal">beat.name</code>.</p><div class="pre_wrapper lang-js"><pre class="programlisting prettyprint lang-js">"aggregations": {
  "beat.name": {
    "terms": {
      "field": "beat.name"
    },
    "aggregations": {
      "buckets": {
        "date_histogram": {
          "field": "@timestamp",
          "fixed_interval": "5m"
        },
        "aggregations": {
          "@timestamp": {
            "max": {
              "field": "@timestamp"
            }
          },
          "bytes_out_average": {
            "avg": {
              "field": "system.network.out.bytes"
            }
          },
          "bytes_out_derivative": {
            "derivative": {
              "buckets_path": "bytes_out_average"
            }
          }
        }
      }
    }
  }
}</pre></div><p>Datafeeds not only supports multi-bucket aggregations, but also single bucket aggregations.
The following shows two <code class="literal">filter</code> aggregations, each gathering the number of unique entries for
the <code class="literal">error</code> field.</p><div class="pre_wrapper lang-js"><pre class="programlisting prettyprint lang-js">{
  "job_id":"servers-unique-errors",
  "indices": ["logs-*"],
  "aggregations": {
    "buckets": {
      "date_histogram": {
        "field": "time",
        "interval": "360s",
        "time_zone": "UTC"
      },
      "aggregations": {
        "time": {
          "max": {"field": "time"}
        }
        "server1": {
          "filter": {"term": {"source": "server-name-1"}},
          "aggregations": {
            "server1_error_count": {
              "value_count": {
                "field": "error"
              }
            }
          }
        },
        "server2": {
          "filter": {"term": {"source": "server-name-2"}},
          "aggregations": {
            "server2_error_count": {
              "value_count": {
                "field": "error"
              }
            }
          }
        }
      }
    }
  }
}</pre></div><p>When you define an aggregation in a datafeed, it must have the following form:</p><div class="pre_wrapper lang-js"><pre class="programlisting prettyprint lang-js">"aggregations": {
  ["bucketing_aggregation": {
    "bucket_agg": {
      ...
    },
    "aggregations": {]
      "data_histogram_aggregation": {
        "date_histogram": {
          "field": "time",
        },
        "aggregations": {
          "timestamp": {
            "max": {
              "field": "time"
            }
          },
          [,"&lt;first_term&gt;": {
            "terms":{...
            }
            [,"aggregations" : {
              [&lt;sub_aggregation&gt;]+
            } ]
          }]
        }
      }
    }
  }
}</pre></div><p>The top level aggregation must be either a <a class="ulink" href="https://www.elastic.co/guide/en/elasticsearch/reference/master/search-aggregations-bucket.html" target="_top">Bucket Aggregation</a>
containing as single sub-aggregation that is a <code class="literal">date_histogram</code> or the top level aggregation
is the required <code class="literal">date_histogram</code>. There must be exactly 1 <code class="literal">date_histogram</code> aggregation.
For more information, see
<a class="ulink" href="https://www.elastic.co/guide/en/elasticsearch/reference/master/search-aggregations-bucket-datehistogram-aggregation.html" target="_top">Date Histogram Aggregation</a>.</p><div class="note admon"><div class="icon"><img alt="Note" src="images/icons/note.png" /></div><div class="admon_content"><p>The <code class="literal">time_zone</code> parameter in the date histogram aggregation must be set to <code class="literal">UTC</code>,
which is the default value.</p></div></div><p>Each histogram bucket has a key, which is the bucket start time. This key cannot
be used for aggregations in datafeeds, however, because they need to know the
time of the latest record within a bucket. Otherwise, when you restart a datafeed,
it continues from the start time of the histogram bucket and possibly fetches
the same data twice. The max aggregation for the time field is therefore
necessary to provide the time of the latest record within a bucket.</p><p>You can optionally specify a terms aggregation, which creates buckets for
different values of a field.</p><div class="important admon"><div class="icon"><img alt="Important" src="images/icons/important.png" /></div><div class="admon_content"><p>If you use a terms aggregation, by default it returns buckets for
the top ten terms. Thus if the cardinality of the term is greater than 10, not
all terms are analyzed.</p></div></div><p>You can change this behavior by setting the <code class="literal">size</code> parameter. To
determine the cardinality of your data, you can run searches such as:</p><div class="pre_wrapper lang-js"><pre class="programlisting prettyprint lang-js">GET .../_search {
  "aggs": {
    "service_cardinality": {
      "cardinality": {
        "field": "service"
        }
    }
  }
}</pre></div><p>By default, Elasticsearch limits the maximum number of terms returned to 10000. For high
cardinality fields, the query might not run. It might return errors related to
circuit breaking exceptions that indicate that the data is too large. In such
cases, do not use aggregations in your datafeed. For more
information, see <a class="ulink" href="https://www.elastic.co/guide/en/elasticsearch/reference/master/search-aggregations-bucket-terms-aggregation.html" target="_top">Terms Aggregation</a>.</p><p>You can also optionally specify multiple sub-aggregations.
The sub-aggregations are aggregated for the buckets that were created by their
parent aggregation. For more information, see
<a class="ulink" href="https://www.elastic.co/guide/en/elasticsearch/reference/master/search-aggregations.html" target="_top">Aggregations</a>.</p><div class="tip admon"><div class="icon"><img alt="Tip" src="images/icons/tip.png" /></div><div class="admon_content"><p>If your detectors use metric or sum analytical functions, set the
<code class="literal">interval</code> of the date histogram aggregation to a tenth of the <code class="literal">bucket_span</code>
that was defined in the job. This suggestion creates finer, more granular time
buckets, which are ideal for this type of analysis. If your detectors use count
or rare functions, set <code class="literal">interval</code> to the same value as <code class="literal">bucket_span</code>. For more
information about analytical functions, see <a class="xref" href="ml-functions.html" title="Function reference">Function reference</a>.</p></div></div></div><div class="xpack section"><div class="titlepage"><div><div><h3 class="title"><a id="ml-configuring-detector-custom-rules"></a>Customizing detectors with custom rules<a href="https://github.com/elastic/elasticsearch/edit/master/docs/reference/ml/anomaly-detection/detector-custom-rules.asciidoc" class="edit_me" title="Edit this page on GitHub" rel="nofollow">edit</a><a class="xpack_tag" href="/subscriptions"></a></h3></div></div></div><p><a class="link" href="ml-rules.html" title="Custom rules">Custom rules</a> enable you to change the behavior of anomaly
detectors based on domain-specific knowledge.</p><p>Custom rules describe <span class="emphasis"><em>when</em></span> a detector should take a certain <span class="emphasis"><em>action</em></span> instead
of following its default behavior. To specify the <span class="emphasis"><em>when</em></span> a rule uses
a <code class="literal">scope</code> and <code class="literal">conditions</code>. You can think of <code class="literal">scope</code> as the categorical
specification of a rule, while <code class="literal">conditions</code> are the numerical part.
A rule can have a scope, one or more conditions, or a combination of
scope and conditions.</p><p>Let us see how those can be configured by examples.</p><div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="_specifying_custom_rule_scope"></a>Specifying custom rule scope<a href="https://github.com/elastic/elasticsearch/edit/master/docs/reference/ml/anomaly-detection/detector-custom-rules.asciidoc" class="edit_me" title="Edit this page on GitHub" rel="nofollow">edit</a></h4></div></div></div><p>Let us assume we are configuring an anomaly detection job in order to detect DNS data
exfiltration. Our data contain fields "subdomain" and "highest_registered_domain".
We can use a detector that looks like
<code class="literal">high_info_content(subdomain) over highest_registered_domain</code>. If we run such a
job, it is possible that we discover a lot of anomalies on frequently used
domains that we have reasons to trust. As security analysts, we are not
interested in such anomalies. Ideally, we could instruct the detector to skip
results for domains that we consider safe. Using a rule with a scope allows us
to achieve this.</p><p>First, we need to create a list of our safe domains. Those lists are called
<span class="emphasis"><em>filters</em></span> in machine learning. Filters can be shared across anomaly detection jobs.</p><p>We create our filter using the <a class="ulink" href="https://www.elastic.co/guide/en/elasticsearch/reference/master/ml-put-filter.html" target="_top">put filter API</a>:</p><div class="pre_wrapper lang-console"><pre class="programlisting prettyprint lang-console">PUT _ml/filters/safe_domains
{
  "description": "Our list of safe domains",
  "items": ["safe.com", "trusted.com"]
}</pre></div><div class="console_widget" data-snippet="snippets/78.console"></div><p>Now, we can create our anomaly detection job specifying a scope that uses the
<code class="literal">safe_domains</code>  filter for the <code class="literal">highest_registered_domain</code> field:</p><div class="pre_wrapper lang-console"><pre class="programlisting prettyprint lang-console">PUT _ml/anomaly_detectors/dns_exfiltration_with_rule
{
  "analysis_config" : {
    "bucket_span":"5m",
    "detectors" :[{
      "function":"high_info_content",
      "field_name": "subdomain",
      "over_field_name": "highest_registered_domain",
      "custom_rules": [{
        "actions": ["skip_result"],
        "scope": {
          "highest_registered_domain": {
            "filter_id": "safe_domains",
            "filter_type": "include"
          }
        }
      }]
    }]
  },
  "data_description" : {
    "time_field":"timestamp"
  }
}</pre></div><div class="console_widget" data-snippet="snippets/79.console"></div><p>As time advances and we see more data and more results, we might encounter new
domains that we want to add in the filter. We can do that by using the
<a class="ulink" href="https://www.elastic.co/guide/en/elasticsearch/reference/master/ml-update-filter.html" target="_top">update filter API</a>:</p><div class="pre_wrapper lang-console"><pre class="programlisting prettyprint lang-console">POST _ml/filters/safe_domains/_update
{
  "add_items": ["another-safe.com"]
}</pre></div><div class="console_widget" data-snippet="snippets/80.console"></div><p>Note that we can use any of the <code class="literal">partition_field_name</code>, <code class="literal">over_field_name</code>, or
<code class="literal">by_field_name</code> fields in the <code class="literal">scope</code>.</p><p>In the following example we scope multiple fields:</p><div class="pre_wrapper lang-console"><pre class="programlisting prettyprint lang-console">PUT _ml/anomaly_detectors/scoping_multiple_fields
{
  "analysis_config" : {
    "bucket_span":"5m",
    "detectors" :[{
      "function":"count",
      "partition_field_name": "my_partition",
      "over_field_name": "my_over",
      "by_field_name": "my_by",
      "custom_rules": [{
        "actions": ["skip_result"],
        "scope": {
          "my_partition": {
            "filter_id": "filter_1"
          },
          "my_over": {
            "filter_id": "filter_2"
          },
          "my_by": {
            "filter_id": "filter_3"
          }
        }
      }]
    }]
  },
  "data_description" : {
    "time_field":"timestamp"
  }
}</pre></div><div class="console_widget" data-snippet="snippets/81.console"></div><p>Such a detector will skip results when the values of all 3 scoped fields
are included in the referenced filters.</p></div><div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="_specifying_custom_rule_conditions"></a>Specifying custom rule conditions<a href="https://github.com/elastic/elasticsearch/edit/master/docs/reference/ml/anomaly-detection/detector-custom-rules.asciidoc" class="edit_me" title="Edit this page on GitHub" rel="nofollow">edit</a></h4></div></div></div><p>Imagine a detector that looks for anomalies in CPU utilization.
Given a machine that is idle for long enough, small movement in CPU could
result in anomalous results where the <code class="literal">actual</code> value is quite small, for
example, 0.02. Given our knowledge about how CPU utilization behaves we might
determine that anomalies with such small actual values are not interesting for
investigation.</p><p>Let us now configure an anomaly detection job with a rule that will skip results where
CPU utilization is less than 0.20.</p><div class="pre_wrapper lang-console"><pre class="programlisting prettyprint lang-console">PUT _ml/anomaly_detectors/cpu_with_rule
{
  "analysis_config" : {
    "bucket_span":"5m",
    "detectors" :[{
      "function":"high_mean",
      "field_name": "cpu_utilization",
      "custom_rules": [{
        "actions": ["skip_result"],
        "conditions": [
          {
            "applies_to": "actual",
            "operator": "lt",
            "value": 0.20
          }
        ]
      }]
    }]
  },
  "data_description" : {
    "time_field":"timestamp"
  }
}</pre></div><div class="console_widget" data-snippet="snippets/82.console"></div><p>When there are multiple conditions they are combined with a logical <code class="literal">and</code>.
This is useful when we want the rule to apply to a range. We simply create
a rule with two conditions, one for each end of the desired range.</p><p>Here is an example where a count detector will skip results when the count
is greater than 30 and less than 50:</p><div class="pre_wrapper lang-console"><pre class="programlisting prettyprint lang-console">PUT _ml/anomaly_detectors/rule_with_range
{
  "analysis_config" : {
    "bucket_span":"5m",
    "detectors" :[{
      "function":"count",
      "custom_rules": [{
        "actions": ["skip_result"],
        "conditions": [
          {
            "applies_to": "actual",
            "operator": "gt",
            "value": 30
          },
          {
            "applies_to": "actual",
            "operator": "lt",
            "value": 50
          }
        ]
      }]
    }]
  },
  "data_description" : {
    "time_field":"timestamp"
  }
}</pre></div><div class="console_widget" data-snippet="snippets/83.console"></div></div><div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="_custom_rules_in_the_life_cycle_of_a_job"></a>Custom rules in the life-cycle of a job<a href="https://github.com/elastic/elasticsearch/edit/master/docs/reference/ml/anomaly-detection/detector-custom-rules.asciidoc" class="edit_me" title="Edit this page on GitHub" rel="nofollow">edit</a></h4></div></div></div><p>Custom rules only affect results created after the rules were applied.
Let us imagine that we have configured an anomaly detection job and it has been running
for some time. After observing its results we decide that we can employ
rules in order to get rid of some uninteresting results. We can use
the <a class="ulink" href="https://www.elastic.co/guide/en/elasticsearch/reference/master/ml-update-job.html" target="_top">update anomaly detection job API</a> to do so. However, the
rule we added will only be in effect for any results created from the moment we
added  the rule onwards. Past results will remain unaffected.</p></div><div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="_using_custom_rules_vs_filtering_data"></a>Using custom rules vs. filtering data<a href="https://github.com/elastic/elasticsearch/edit/master/docs/reference/ml/anomaly-detection/detector-custom-rules.asciidoc" class="edit_me" title="Edit this page on GitHub" rel="nofollow">edit</a></h4></div></div></div><p>It might appear like using rules is just another way of filtering the data
that feeds into an anomaly detection job. For example, a rule that skips results when
the partition field value is in a filter sounds equivalent to having a query
that filters out such documents. But it is not. There is a fundamental
difference. When the data is filtered before reaching a job it is as if they
never existed for the job. With rules, the data still reaches the job and
affects its behavior (depending on the rule actions).</p><p>For example, a rule with the <code class="literal">skip_result</code> action means all data will still
be modeled. On the other hand, a rule with the <code class="literal">skip_model_update</code> action means
results will still be created even though the model will not be updated by
data matched by a rule.</p></div></div><div class="xpack section"><div class="titlepage"><div><div><h3 class="title"><a id="ml-configuring-categories"></a>Categorizing log messages<a href="https://github.com/elastic/elasticsearch/edit/master/docs/reference/ml/anomaly-detection/categories.asciidoc" class="edit_me" title="Edit this page on GitHub" rel="nofollow">edit</a><a class="xpack_tag" href="/subscriptions"></a></h3></div></div></div><p>Application log events are often unstructured and contain variable data. For
example:</p><div class="pre_wrapper lang-js"><pre class="programlisting prettyprint lang-js">{"time":1454516381000,"message":"org.jdbi.v2.exceptions.UnableToExecuteStatementException: com.mysql.jdbc.exceptions.MySQLTimeoutException: Statement cancelled due to timeout or client request [statement:\"SELECT id, customer_id, name, force_disabled, enabled FROM customers\"]","type":"logs"}</pre></div><p>You can use machine learning to observe the static parts of the message, cluster similar
messages together, and classify them into message categories.</p><p>The machine learning model learns what volume and pattern is normal for each category over
time. You can then detect anomalies and surface rare events or unusual types of
messages by using count or rare functions. For example:</p><div class="pre_wrapper lang-console"><pre class="programlisting prettyprint lang-console">PUT _ml/anomaly_detectors/it_ops_new_logs
{
  "description" : "IT Ops Application Logs",
  "analysis_config" : {
    "categorization_field_name": "message", <a id="CO57-1"></a><i class="conum" data-value="1"></i>
    "bucket_span":"30m",
    "detectors" :[{
      "function":"count",
      "by_field_name": "mlcategory", <a id="CO57-2"></a><i class="conum" data-value="2"></i>
      "detector_description": "Unusual message counts"
    }],
    "categorization_filters":[ "\\[statement:.*\\]"]
  },
  "analysis_limits":{
    "categorization_examples_limit": 5
  },
  "data_description" : {
    "time_field":"time",
    "time_format": "epoch_ms"
  }
}</pre></div><div class="console_widget" data-snippet="snippets/84.console"></div><div class="calloutlist"><table border="0" summary="Callout list"><tr><td width="5%" valign="top" align="left"><p><a href="#CO57-1"><i class="conum" data-value="1"></i></a> </p></td><td valign="top" align="left"><p>The <code class="literal">categorization_field_name</code> property indicates which field will be
categorized.</p></td></tr><tr><td width="5%" valign="top" align="left"><p><a href="#CO57-2"><i class="conum" data-value="2"></i></a> </p></td><td valign="top" align="left"><p>The resulting categories are used in a detector by setting <code class="literal">by_field_name</code>,
<code class="literal">over_field_name</code>, or <code class="literal">partition_field_name</code> to the keyword <code class="literal">mlcategory</code>. If you
do not specify this keyword in one of those properties, the API request fails.</p></td></tr></table></div><p>The optional <code class="literal">categorization_examples_limit</code> property specifies the
maximum number of examples that are stored in memory and in the results data
store for each category. The default value is <code class="literal">4</code>. Note that this setting does
not affect the categorization; it just affects the list of visible examples. If
you increase this value, more examples are available, but you must have more
storage available. If you set this value to <code class="literal">0</code>, no examples are stored.</p><p>The optional <code class="literal">categorization_filters</code> property can contain an array of regular
expressions. If a categorization field value matches the regular expression, the
portion of the field that is matched is not taken into consideration when
defining categories. The categorization filters are applied in the order they
are listed in the job configuration, which allows you to disregard multiple
sections of the categorization field value. In this example, we have decided that
we do not want the detailed SQL to be considered in the message categorization.
This particular categorization filter removes the SQL statement from the categorization
algorithm.</p><p>If your data is stored in Elasticsearch, you can create an advanced anomaly detection job with
these same properties:</p><div class="screenshot informalfigure"><div class="mediaobject"><img src="images/ml-category-advanced.jpg" alt="Advanced job configuration options related to categorization" /></div></div><div class="note admon"><div class="icon"><img alt="Note" src="images/icons/note.png" /></div><div class="admon_content"><p>To add the <code class="literal">categorization_examples_limit</code> property, you must use the
<span class="strong strong"><strong>Edit JSON</strong></span> tab and copy the <code class="literal">analysis_limits</code> object from the API example.</p></div></div><h5><a id="ml-configuring-analyzer"></a>Customizing the categorization analyzer<a href="https://github.com/elastic/elasticsearch/edit/master/docs/reference/ml/anomaly-detection/categories.asciidoc" class="edit_me" title="Edit this page on GitHub" rel="nofollow">edit</a></h5><p>Categorization uses English dictionary words to identify log message categories.
By default, it also uses English tokenization rules. For this reason, if you use
the default categorization analyzer, only English language log messages are
supported, as described in the <a class="xref" href="ml-limitations.html" title="Machine learning anomaly detection limitations"><em>Limitations</em></a>.</p><p>You can, however, change the tokenization rules by customizing the way the
categorization field values are interpreted. For example:</p><div class="pre_wrapper lang-console"><pre class="programlisting prettyprint lang-console">PUT _ml/anomaly_detectors/it_ops_new_logs2
{
  "description" : "IT Ops Application Logs",
  "analysis_config" : {
    "categorization_field_name": "message",
    "bucket_span":"30m",
    "detectors" :[{
      "function":"count",
      "by_field_name": "mlcategory",
      "detector_description": "Unusual message counts"
    }],
    "categorization_analyzer":{
      "char_filter": [
        { "type": "pattern_replace", "pattern": "\\[statement:.*\\]" } <a id="CO58-1"></a><i class="conum" data-value="1"></i>
      ],
      "tokenizer": "ml_classic", <a id="CO58-2"></a><i class="conum" data-value="2"></i>
      "filter": [
        { "type" : "stop", "stopwords": [
          "Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday",
          "Mon", "Tue", "Wed", "Thu", "Fri", "Sat", "Sun",
          "January", "February", "March", "April", "May", "June", "July", "August", "September", "October", "November", "December",
          "Jan", "Feb", "Mar", "Apr", "May", "Jun", "Jul", "Aug", "Sep", "Oct", "Nov", "Dec",
          "GMT", "UTC"
        ] } <a id="CO58-3"></a><i class="conum" data-value="3"></i>
      ]
    }
  },
  "analysis_limits":{
    "categorization_examples_limit": 5
  },
  "data_description" : {
    "time_field":"time",
    "time_format": "epoch_ms"
  }
}</pre></div><div class="console_widget" data-snippet="snippets/85.console"></div><div class="calloutlist"><table border="0" summary="Callout list"><tr><td width="5%" valign="top" align="left"><p><a href="#CO58-1"><i class="conum" data-value="1"></i></a> </p></td><td valign="top" align="left"><p>The
<a class="ulink" href="https://www.elastic.co/guide/en/elasticsearch/reference/master/analysis-pattern-replace-charfilter.html" target="_top"><code class="literal">pattern_replace</code> character filter</a>
here achieves exactly the same as the <code class="literal">categorization_filters</code> in the first
example.</p></td></tr><tr><td width="5%" valign="top" align="left"><p><a href="#CO58-2"><i class="conum" data-value="2"></i></a> </p></td><td valign="top" align="left"><p>The <code class="literal">ml_classic</code> tokenizer works like the non-customizable tokenization
that was used for categorization in older versions of machine learning. If you
want the same categorization behavior as older versions, use this property value.</p></td></tr><tr><td width="5%" valign="top" align="left"><p><a href="#CO58-3"><i class="conum" data-value="3"></i></a> </p></td><td valign="top" align="left"><p>By default, English day or month words are filtered from log messages before
categorization. If your logs are in a different language and contain
dates, you might get better results by filtering the day or month words in your
language.</p></td></tr></table></div><p>The optional <code class="literal">categorization_analyzer</code> property allows even greater customization
of how categorization interprets the categorization field value. It can refer to
a built-in Elasticsearch analyzer or a combination of zero or more character filters,
a tokenizer, and zero or more token filters.</p><p>The <code class="literal">ml_classic</code> tokenizer and the day and month stopword filter are more or less
equivalent to the following analyzer, which is defined using only built-in Elasticsearch
<a class="ulink" href="https://www.elastic.co/guide/en/elasticsearch/reference/master/analysis-tokenizers.html" target="_top">tokenizers</a> and
<a class="ulink" href="https://www.elastic.co/guide/en/elasticsearch/reference/master/analysis-tokenfilters.html" target="_top">token filters</a>:</p><div class="pre_wrapper lang-console"><pre class="programlisting prettyprint lang-console">PUT _ml/anomaly_detectors/it_ops_new_logs3
{
  "description" : "IT Ops Application Logs",
  "analysis_config" : {
    "categorization_field_name": "message",
    "bucket_span":"30m",
    "detectors" :[{
      "function":"count",
      "by_field_name": "mlcategory",
      "detector_description": "Unusual message counts"
    }],
    "categorization_analyzer":{
      "tokenizer": {
        "type" : "simple_pattern_split",
        "pattern" : "[^-0-9A-Za-z_.]+" <a id="CO59-1"></a><i class="conum" data-value="1"></i>
      },
      "filter": [
        { "type" : "pattern_replace", "pattern": "^[0-9].*" }, <a id="CO59-2"></a><i class="conum" data-value="2"></i>
        { "type" : "pattern_replace", "pattern": "^[-0-9A-Fa-f.]+$" }, <a id="CO59-3"></a><i class="conum" data-value="3"></i>
        { "type" : "pattern_replace", "pattern": "^[^0-9A-Za-z]+" }, <a id="CO59-4"></a><i class="conum" data-value="4"></i>
        { "type" : "pattern_replace", "pattern": "[^0-9A-Za-z]+$" }, <a id="CO59-5"></a><i class="conum" data-value="5"></i>
        { "type" : "stop", "stopwords": [
          "",
          "Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday",
          "Mon", "Tue", "Wed", "Thu", "Fri", "Sat", "Sun",
          "January", "February", "March", "April", "May", "June", "July", "August", "September", "October", "November", "December",
          "Jan", "Feb", "Mar", "Apr", "May", "Jun", "Jul", "Aug", "Sep", "Oct", "Nov", "Dec",
          "GMT", "UTC"
        ] }
      ]
    }
  },
  "analysis_limits":{
    "categorization_examples_limit": 5
  },
  "data_description" : {
    "time_field":"time",
    "time_format": "epoch_ms"
  }
}</pre></div><div class="console_widget" data-snippet="snippets/86.console"></div><div class="calloutlist"><table border="0" summary="Callout list"><tr><td width="5%" valign="top" align="left"><p><a href="#CO59-1"><i class="conum" data-value="1"></i></a> </p></td><td valign="top" align="left"><p>Tokens basically consist of hyphens, digits, letters, underscores and dots.</p></td></tr><tr><td width="5%" valign="top" align="left"><p><a href="#CO59-2"><i class="conum" data-value="2"></i></a> </p></td><td valign="top" align="left"><p>By default, categorization ignores tokens that begin with a digit.</p></td></tr><tr><td width="5%" valign="top" align="left"><p><a href="#CO59-3"><i class="conum" data-value="3"></i></a> </p></td><td valign="top" align="left"><p>By default, categorization also ignores tokens that are hexadecimal numbers.</p></td></tr><tr><td width="5%" valign="top" align="left"><p><a href="#CO59-4"><i class="conum" data-value="4"></i></a> </p></td><td valign="top" align="left"><p>Underscores, hyphens, and dots are removed from the beginning of tokens.</p></td></tr><tr><td width="5%" valign="top" align="left"><p><a href="#CO59-5"><i class="conum" data-value="5"></i></a> </p></td><td valign="top" align="left"><p>Underscores, hyphens, and dots are also removed from the end of tokens.</p></td></tr></table></div><p>The key difference between the default <code class="literal">categorization_analyzer</code> and this example
analyzer is that using the <code class="literal">ml_classic</code> tokenizer is several times faster. The
difference in behavior is that this custom analyzer does not include accented
letters in tokens whereas the <code class="literal">ml_classic</code> tokenizer does, although that could
be fixed by using more complex regular expressions.</p><p>For more information about the <code class="literal">categorization_analyzer</code> property, see
<a class="ulink" href="https://www.elastic.co/guide/en/elasticsearch/reference/master/ml-job-resource.html#ml-categorizationanalyzer" target="_top">Categorization analyzer</a>.</p><div class="note admon"><div class="icon"><img alt="Note" src="images/icons/note.png" /></div><div class="admon_content"><p>To add the <code class="literal">categorization_analyzer</code> property in Kibana, you must use the
<span class="strong strong"><strong>Edit JSON</strong></span> tab and copy the <code class="literal">categorization_analyzer</code> object from one of the
API examples above.</p></div></div><h5><a id="ml-viewing-categories"></a>Viewing categorization results<a href="https://github.com/elastic/elasticsearch/edit/master/docs/reference/ml/anomaly-detection/categories.asciidoc" class="edit_me" title="Edit this page on GitHub" rel="nofollow">edit</a></h5><p>After you open the job and start the datafeed or supply data to the job, you can
view the categorization results in Kibana. For example:</p><div class="screenshot informalfigure"><div class="mediaobject"><img src="images/ml-category-anomalies.jpg" alt="Categorization example in the Anomaly Explorer" /></div></div><p>For this type of job, the <span class="strong strong"><strong>Anomaly Explorer</strong></span> contains extra information for
each anomaly: the name of the category (for example, <code class="literal">mlcategory 11</code>) and
examples of the messages in that category. In this case, you can use these
details to investigate occurrences of unusually high message counts for specific
message categories.</p></div><div class="xpack section"><div class="titlepage"><div><div><h3 class="title"><a id="ml-configuring-pop"></a>Performing population analysis<a href="https://github.com/elastic/elasticsearch/edit/master/docs/reference/ml/anomaly-detection/populations.asciidoc" class="edit_me" title="Edit this page on GitHub" rel="nofollow">edit</a><a class="xpack_tag" href="/subscriptions"></a></h3></div></div></div><p>Entities or events in your data can be considered anomalous when:</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">Their behavior changes over time, relative to their own previous behavior, or</li><li class="listitem">Their behavior is different than other entities in a specified population.</li></ul></div><p>The latter method of detecting outliers is known as <span class="emphasis"><em>population analysis</em></span>. The
machine learning analytics build a profile of what a "typical" user, machine, or other entity
does over a specified time period and then identify when one is behaving
abnormally compared to the population.</p><p>This type of analysis is most useful when the behavior of the population as a
whole is mostly homogeneous and you want to identify outliers. In general,
population analysis is not useful when members of the population inherently
have vastly different behavior. You can, however, segment your data into groups
that behave similarly and run these as separate jobs. For example, you can use a
query filter in the datafeed to segment your data or you can use the
<code class="literal">partition_field_name</code> to split the analysis for the different groups.</p><p>Population analysis scales well and has a lower resource footprint than
individual analysis of each series. For example, you can analyze populations
of hundreds of thousands or millions of entities.</p><p>To specify the population, use the <code class="literal">over_field_name</code> property. For example:</p><div class="pre_wrapper lang-console"><pre class="programlisting prettyprint lang-console">PUT _ml/anomaly_detectors/population
{
  "description" : "Population analysis",
  "analysis_config" : {
    "bucket_span":"15m",
    "influencers": [
      "clientip"
    ],
    "detectors": [
      {
        "function": "mean",
        "field_name": "bytes",
        "over_field_name": "clientip" <a id="CO60-1"></a><i class="conum" data-value="1"></i>
      }
    ]
  },
  "data_description" : {
    "time_field":"timestamp",
    "time_format": "epoch_ms"
  }
}</pre></div><div class="console_widget" data-snippet="snippets/87.console"></div><div class="calloutlist"><table border="0" summary="Callout list"><tr><td width="5%" valign="top" align="left"><p><a href="#CO60-1"><i class="conum" data-value="1"></i></a> </p></td><td valign="top" align="left"><p>This <code class="literal">over_field_name</code> property indicates that the metrics for each client (
as identified by their IP address) are analyzed relative to other clients
in each bucket.</p></td></tr></table></div><p>If your data is stored in Elasticsearch, you can use the population job wizard in Kibana
to create an anomaly detection job with these same properties. For example, if you add
the sample web logs in Kibana, you can use the following job settings in the
population job wizard:</p><div class="screenshot informalfigure"><div class="mediaobject"><img src="images/ml-population-job.jpg" alt="&quot;Job settings in the population job wizard" /></div></div><p>After you open the job and start the datafeed or supply data to the job, you can
view the results in Kibana. For example, you can view the results in the
<span class="strong strong"><strong>Anomaly Explorer</strong></span>:</p><div class="screenshot informalfigure"><div class="mediaobject"><img src="images/ml-population-results.jpg" alt="Population analysis results in the Anomaly Explorer" /></div></div><p>As in this case, the results are often quite sparse. There might be just a few
data points for the selected time period. Population analysis is particularly
useful when you have many entities and the data for specific entitles is sporadic
or sparse.</p><p>If you click on a section in the timeline or swimlanes, you can see more
details about the anomalies:</p><div class="screenshot informalfigure"><div class="mediaobject"><img src="images/ml-population-anomaly.jpg" alt="Anomaly details for a specific user" /></div></div><p>In this example, the client IP address <code class="literal">29.64.62.83</code> received a high volume of
bytes on the date and time shown. This event is anomalous because the mean is
three times higher than the expected behavior of the population.</p></div><div class="xpack section"><div class="titlepage"><div><div><h3 class="title"><a id="ml-configuring-transform"></a>Transforming data with script fields<a href="https://github.com/elastic/elasticsearch/edit/master/docs/reference/ml/anomaly-detection/transforms.asciidoc" class="edit_me" title="Edit this page on GitHub" rel="nofollow">edit</a><a class="xpack_tag" href="/subscriptions"></a></h3></div></div></div><p>If you use datafeeds, you can add scripts to transform your data before
it is analyzed. Datafeeds contain an optional <code class="literal">script_fields</code> property, where
you can specify scripts that evaluate custom expressions and return script
fields.</p><p>If your datafeed defines script fields, you can use those fields in your
anomaly detection job. For example, you can use the script fields in the analysis
functions in one or more detectors.</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><a class="xref" href="ml-configuring.html#ml-configuring-transform1" title="Example 1: Adding two numerical fields">Example 1: Adding two numerical fields</a></li><li class="listitem"><a class="xref" href="ml-configuring.html#ml-configuring-transform2" title="Example 2: Concatenating strings">Example 2: Concatenating strings</a></li><li class="listitem"><a class="xref" href="ml-configuring.html#ml-configuring-transform3" title="Example 3: Trimming strings">Example 3: Trimming strings</a></li><li class="listitem"><a class="xref" href="ml-configuring.html#ml-configuring-transform4" title="Example 4: Converting strings to lowercase">Example 4: Converting strings to lowercase</a></li><li class="listitem"><a class="xref" href="ml-configuring.html#ml-configuring-transform5" title="Example 5: Converting strings to mixed case formats">Example 5: Converting strings to mixed case formats</a></li><li class="listitem"><a class="xref" href="ml-configuring.html#ml-configuring-transform6" title="Example 6: Replacing tokens">Example 6: Replacing tokens</a></li><li class="listitem"><a class="xref" href="ml-configuring.html#ml-configuring-transform7" title="Example 7: Regular expression matching and concatenation">Example 7: Regular expression matching and concatenation</a></li><li class="listitem"><a class="xref" href="ml-configuring.html#ml-configuring-transform8" title="Example 8: Splitting strings by domain name">Example 8: Splitting strings by domain name</a></li><li class="listitem"><a class="xref" href="ml-configuring.html#ml-configuring-transform9" title="Example 9: Transforming geo_point data">Example 9: Transforming geo_point data</a></li></ul></div><p>The following index APIs create and add content to an index that is used in
subsequent examples:</p><div class="pre_wrapper lang-console"><pre class="programlisting prettyprint lang-console">PUT /my_index
{
  "mappings":{
    "properties": {
      "@timestamp": {
        "type": "date"
      },
      "aborted_count": {
        "type": "long"
      },
      "another_field": {
        "type": "keyword" <a id="CO61-1"></a><i class="conum" data-value="1"></i>
      },
      "clientip": {
        "type": "keyword"
      },
      "coords": {
        "properties": {
          "lat": {
            "type": "keyword"
          },
          "lon": {
            "type": "keyword"
          }
        }
      },
      "error_count": {
        "type": "long"
      },
      "query": {
        "type": "keyword"
      },
      "some_field": {
        "type": "keyword"
      },
      "tokenstring1":{
        "type":"keyword"
      },
      "tokenstring2":{
        "type":"keyword"
      },
      "tokenstring3":{
        "type":"keyword"
      }
    }
  }
}

PUT /my_index/_doc/1
{
  "@timestamp":"2017-03-23T13:00:00",
  "error_count":36320,
  "aborted_count":4156,
  "some_field":"JOE",
  "another_field":"SMITH  ",
  "tokenstring1":"foo-bar-baz",
  "tokenstring2":"foo bar baz",
  "tokenstring3":"foo-bar-19",
  "query":"www.ml.elastic.co",
  "clientip":"123.456.78.900",
  "coords": {
    "lat" : 41.44,
    "lon":90.5
  }
}</pre></div><div class="console_widget" data-snippet="snippets/88.console"></div><div class="calloutlist"><table border="0" summary="Callout list"><tr><td width="5%" valign="top" align="left"><p><a href="#CO61-1"><i class="conum" data-value="1"></i></a> </p></td><td valign="top" align="left"><p>In this example, string fields are mapped as <code class="literal">keyword</code> fields to support
aggregation. If you want both a full text (<code class="literal">text</code>) and a keyword (<code class="literal">keyword</code>)
version of the same field, use multi-fields. For more information, see
<a class="ulink" href="https://www.elastic.co/guide/en/elasticsearch/reference/master/multi-fields.html" target="_top">fields</a>.</p></td></tr></table></div><p><a id="ml-configuring-transform1"></a><strong>Example 1: Adding two numerical fields. </strong>
</p><div class="pre_wrapper lang-console"><pre class="programlisting prettyprint lang-console">PUT _ml/anomaly_detectors/test1
{
  "analysis_config":{
    "bucket_span": "10m",
    "detectors":[
      {
        "function":"mean",
        "field_name": "total_error_count", <a id="CO62-1"></a><i class="conum" data-value="1"></i>
        "detector_description": "Custom script field transformation"
      }
    ]
  },
  "data_description": {
  "time_field":"@timestamp",
  "time_format":"epoch_ms"
  }
}

PUT _ml/datafeeds/datafeed-test1
{
  "job_id": "test1",
  "indices": ["my_index"],
  "query": {
    "match_all": {
          "boost": 1
    }
  },
  "script_fields": {
    "total_error_count": { <a id="CO62-2"></a><i class="conum" data-value="2"></i>
      "script": {
        "lang": "expression",
        "source": "doc['error_count'].value + doc['aborted_count'].value"
      }
    }
  }
}</pre></div><div class="console_widget" data-snippet="snippets/89.console"></div><p>
</p><div class="calloutlist"><table border="0" summary="Callout list"><tr><td width="5%" valign="top" align="left"><p><a href="#CO62-1"><i class="conum" data-value="1"></i></a> </p></td><td valign="top" align="left"><p>A script field named <code class="literal">total_error_count</code> is referenced in the detector
within the job.</p></td></tr><tr><td width="5%" valign="top" align="left"><p><a href="#CO62-2"><i class="conum" data-value="2"></i></a> </p></td><td valign="top" align="left"><p>The script field is defined in the datafeed.</p></td></tr></table></div><p>This <code class="literal">test1</code> anomaly detection job contains a detector that uses a script field in a
mean analysis function. The <code class="literal">datafeed-test1</code> datafeed defines the script field.
It contains a script that adds two fields in the document to produce a "total"
error count.</p><p>The syntax for the <code class="literal">script_fields</code> property is identical to that used by Elasticsearch.
For more information, see
<a class="ulink" href="https://www.elastic.co/guide/en/elasticsearch/reference/master/search-request-body.html#request-body-search-script-fields" target="_top">Script fields</a>.</p><p>You can preview the contents of the datafeed by using the following API:</p><div class="pre_wrapper lang-console"><pre class="programlisting prettyprint lang-console">GET _ml/datafeeds/datafeed-test1/_preview</pre></div><div class="console_widget" data-snippet="snippets/90.console"></div><p>In this example, the API returns the following results, which contain a sum of
the <code class="literal">error_count</code> and <code class="literal">aborted_count</code> values:</p><div class="pre_wrapper lang-js"><pre class="programlisting prettyprint lang-js">[
  {
    "@timestamp": 1490274000000,
    "total_error_count": 40476
  }
]</pre></div><div class="note admon"><div class="icon"><img alt="Note" src="images/icons/note.png" /></div><div class="admon_content"><p>This example demonstrates how to use script fields, but it contains
insufficient data to generate meaningful results.</p></div></div><p>You can alternatively use Kibana to create an advanced anomaly detection job that uses
script fields. To add the <code class="literal">script_fields</code> property to your datafeed, you must use
the <span class="strong strong"><strong>Edit JSON</strong></span> tab. For example:</p><div class="screenshot informalfigure"><div class="mediaobject"><img src="images/ml-scriptfields.jpg" alt="Adding script fields to a datafeed in Kibana" /></div></div><div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="ml-configuring-transform-examples"></a>Common script field examples<a href="https://github.com/elastic/elasticsearch/edit/master/docs/reference/ml/anomaly-detection/transforms.asciidoc" class="edit_me" title="Edit this page on GitHub" rel="nofollow">edit</a></h4></div></div></div><p>While the possibilities are limitless, there are a number of common scenarios
where you might use script fields in your datafeeds.</p><div class="note admon"><div class="icon"><img alt="Note" src="images/icons/note.png" /></div><div class="admon_content"><p>Some of these examples use regular expressions. By default, regular
expressions are disabled because they circumvent the protection that Painless
provides against long running and memory hungry scripts. For more information,
see <a class="ulink" href="https://www.elastic.co/guide/en/elasticsearch/reference/master/modules-scripting-painless.html" target="_top">Painless scripting language</a>.</p><p>Machine learning analysis is case sensitive. For example, "John" is considered
to be different than "john". This is one reason you might consider using scripts
that convert your strings to upper or lowercase letters.</p></div></div><p><a id="ml-configuring-transform2"></a><strong>Example 2: Concatenating strings. </strong>
</p><div class="pre_wrapper lang-console"><pre class="programlisting prettyprint lang-console">PUT _ml/anomaly_detectors/test2
{
  "analysis_config":{
    "bucket_span": "10m",
    "detectors":[
      {
        "function":"low_info_content",
        "field_name":"my_script_field", <a id="CO63-1"></a><i class="conum" data-value="1"></i>
        "detector_description": "Custom script field transformation"
      }
    ]
  },
  "data_description": {
  "time_field":"@timestamp",
  "time_format":"epoch_ms"
  }
}

PUT _ml/datafeeds/datafeed-test2
{
  "job_id": "test2",
  "indices": ["my_index"],
  "query": {
    "match_all": {
          "boost": 1
    }
  },
  "script_fields": {
    "my_script_field": {
      "script": {
        "lang": "painless",
        "source": "doc['some_field'].value + '_' + doc['another_field'].value" <a id="CO63-2"></a><i class="conum" data-value="2"></i>
      }
    }
  }
}

GET _ml/datafeeds/datafeed-test2/_preview</pre></div><div class="console_widget" data-snippet="snippets/91.console"></div><p>
</p><div class="calloutlist"><table border="0" summary="Callout list"><tr><td width="5%" valign="top" align="left"><p><a href="#CO63-1"><i class="conum" data-value="1"></i></a> </p></td><td valign="top" align="left"><p>The script field has a rather generic name in this case, since it will
be used for various tests in the subsequent examples.</p></td></tr><tr><td width="5%" valign="top" align="left"><p><a href="#CO63-2"><i class="conum" data-value="2"></i></a> </p></td><td valign="top" align="left"><p>The script field uses the plus (+) operator to concatenate strings.</p></td></tr></table></div><p>The preview datafeed API returns the following results, which show that "JOE"
and "SMITH  " have been concatenated and an underscore was added:</p><div class="pre_wrapper lang-js"><pre class="programlisting prettyprint lang-js">[
  {
    "@timestamp": 1490274000000,
    "my_script_field": "JOE_SMITH  "
  }
]</pre></div><p><a id="ml-configuring-transform3"></a><strong>Example 3: Trimming strings. </strong>
</p><div class="pre_wrapper lang-console"><pre class="programlisting prettyprint lang-console">POST _ml/datafeeds/datafeed-test2/_update
{
  "script_fields": {
    "my_script_field": {
      "script": {
        "lang": "painless",
        "source": "doc['another_field'].value.trim()" <a id="CO64-1"></a><i class="conum" data-value="1"></i>
      }
    }
  }
}

GET _ml/datafeeds/datafeed-test2/_preview</pre></div><div class="console_widget" data-snippet="snippets/92.console"></div><p>
</p><div class="calloutlist"><table border="0" summary="Callout list"><tr><td width="5%" valign="top" align="left"><p><a href="#CO64-1"><i class="conum" data-value="1"></i></a> </p></td><td valign="top" align="left"><p>This script field uses the <code class="literal">trim()</code> function to trim extra white space from a
string.</p></td></tr></table></div><p>The preview datafeed API returns the following results, which show that "SMITH  "
has been trimmed to "SMITH":</p><div class="pre_wrapper lang-js"><pre class="programlisting prettyprint lang-js">[
  {
    "@timestamp": 1490274000000,
    "my_script_field": "SMITH"
  }
]</pre></div><p><a id="ml-configuring-transform4"></a><strong>Example 4: Converting strings to lowercase. </strong>
</p><div class="pre_wrapper lang-console"><pre class="programlisting prettyprint lang-console">POST _ml/datafeeds/datafeed-test2/_update
{
  "script_fields": {
    "my_script_field": {
      "script": {
        "lang": "painless",
        "source": "doc['some_field'].value.toLowerCase()" <a id="CO65-1"></a><i class="conum" data-value="1"></i>
      }
    }
  }
}

GET _ml/datafeeds/datafeed-test2/_preview</pre></div><div class="console_widget" data-snippet="snippets/93.console"></div><p>
</p><div class="calloutlist"><table border="0" summary="Callout list"><tr><td width="5%" valign="top" align="left"><p><a href="#CO65-1"><i class="conum" data-value="1"></i></a> </p></td><td valign="top" align="left"><p>This script field uses the <code class="literal">toLowerCase</code> function to convert a string to all
lowercase letters. Likewise, you can use the <code class="literal">toUpperCase{}</code> function to convert
a string to uppercase letters.</p></td></tr></table></div><p>The preview datafeed API returns the following results, which show that "JOE"
has been converted to "joe":</p><div class="pre_wrapper lang-js"><pre class="programlisting prettyprint lang-js">[
  {
    "@timestamp": 1490274000000,
    "my_script_field": "joe"
  }
]</pre></div><p><a id="ml-configuring-transform5"></a><strong>Example 5: Converting strings to mixed case formats. </strong>
</p><div class="pre_wrapper lang-console"><pre class="programlisting prettyprint lang-console">POST _ml/datafeeds/datafeed-test2/_update
{
  "script_fields": {
    "my_script_field": {
      "script": {
        "lang": "painless",
        "source": "doc['some_field'].value.substring(0, 1).toUpperCase() + doc['some_field'].value.substring(1).toLowerCase()" <a id="CO66-1"></a><i class="conum" data-value="1"></i>
      }
    }
  }
}

GET _ml/datafeeds/datafeed-test2/_preview</pre></div><div class="console_widget" data-snippet="snippets/94.console"></div><p>
</p><div class="calloutlist"><table border="0" summary="Callout list"><tr><td width="5%" valign="top" align="left"><p><a href="#CO66-1"><i class="conum" data-value="1"></i></a> </p></td><td valign="top" align="left"><p>This script field is a more complicated example of case manipulation. It uses
the <code class="literal">subString()</code> function to capitalize the first letter of a string and
converts the remaining characters to lowercase.</p></td></tr></table></div><p>The preview datafeed API returns the following results, which show that "JOE"
has been converted to "Joe":</p><div class="pre_wrapper lang-js"><pre class="programlisting prettyprint lang-js">[
  {
    "@timestamp": 1490274000000,
    "my_script_field": "Joe"
  }
]</pre></div><p><a id="ml-configuring-transform6"></a><strong>Example 6: Replacing tokens. </strong>
</p><div class="pre_wrapper lang-console"><pre class="programlisting prettyprint lang-console">POST _ml/datafeeds/datafeed-test2/_update
{
  "script_fields": {
    "my_script_field": {
      "script": {
        "lang": "painless",
        "source": "/\\s/.matcher(doc['tokenstring2'].value).replaceAll('_')" <a id="CO67-1"></a><i class="conum" data-value="1"></i>
      }
    }
  }
}

GET _ml/datafeeds/datafeed-test2/_preview</pre></div><div class="console_widget" data-snippet="snippets/95.console"></div><p>
</p><div class="calloutlist"><table border="0" summary="Callout list"><tr><td width="5%" valign="top" align="left"><p><a href="#CO67-1"><i class="conum" data-value="1"></i></a> </p></td><td valign="top" align="left"><p>This script field uses regular expressions to replace white
space with underscores.</p></td></tr></table></div><p>The preview datafeed API returns the following results, which show that
"foo bar baz" has been converted to "foo_bar_baz":</p><div class="pre_wrapper lang-js"><pre class="programlisting prettyprint lang-js">[
  {
    "@timestamp": 1490274000000,
    "my_script_field": "foo_bar_baz"
  }
]</pre></div><p><a id="ml-configuring-transform7"></a><strong>Example 7: Regular expression matching and concatenation. </strong>
</p><div class="pre_wrapper lang-console"><pre class="programlisting prettyprint lang-console">POST _ml/datafeeds/datafeed-test2/_update
{
  "script_fields": {
    "my_script_field": {
      "script": {
        "lang": "painless",
        "source": "def m = /(.*)-bar-([0-9][0-9])/.matcher(doc['tokenstring3'].value); return m.find() ? m.group(1) + '_' + m.group(2) : '';" <a id="CO68-1"></a><i class="conum" data-value="1"></i>
      }
    }
  }
}

GET _ml/datafeeds/datafeed-test2/_preview</pre></div><div class="console_widget" data-snippet="snippets/96.console"></div><p>
</p><div class="calloutlist"><table border="0" summary="Callout list"><tr><td width="5%" valign="top" align="left"><p><a href="#CO68-1"><i class="conum" data-value="1"></i></a> </p></td><td valign="top" align="left"><p>This script field looks for a specific regular expression pattern and emits the
matched groups as a concatenated string. If no match is found, it emits an empty
string.</p></td></tr></table></div><p>The preview datafeed API returns the following results, which show that
"foo-bar-19" has been converted to "foo_19":</p><div class="pre_wrapper lang-js"><pre class="programlisting prettyprint lang-js">[
  {
    "@timestamp": 1490274000000,
    "my_script_field": "foo_19"
  }
]</pre></div><p><a id="ml-configuring-transform8"></a><strong>Example 8: Splitting strings by domain name. </strong>
</p><div class="pre_wrapper lang-console"><pre class="programlisting prettyprint lang-console">PUT _ml/anomaly_detectors/test3
{
  "description":"DNS tunneling",
  "analysis_config":{
    "bucket_span": "30m",
    "influencers": ["clientip","hrd"],
    "detectors":[
      {
        "function":"high_info_content",
        "field_name": "sub",
        "over_field_name": "hrd",
        "exclude_frequent":"all"
      }
    ]
  },
  "data_description": {
  "time_field":"@timestamp",
  "time_format":"epoch_ms"
  }
}

PUT _ml/datafeeds/datafeed-test3
{
  "job_id": "test3",
  "indices": ["my_index"],
  "query": {
    "match_all": {
          "boost": 1
    }
  },
  "script_fields":{
    "sub":{
      "script":"return domainSplit(doc['query'].value).get(0);"
    },
    "hrd":{
      "script":"return domainSplit(doc['query'].value).get(1);"
    }
  }
}

GET _ml/datafeeds/datafeed-test3/_preview</pre></div><div class="console_widget" data-snippet="snippets/97.console"></div><p>
</p><p>If you have a single field that contains a well-formed DNS domain name, you can
use the <code class="literal">domainSplit()</code> function to split the string into its highest registered
domain and the sub-domain, which is everything to the left of the highest
registered domain. For example, the highest registered domain of
<code class="literal">www.ml.elastic.co</code> is <code class="literal">elastic.co</code> and the sub-domain is <code class="literal">www.ml</code>. The
<code class="literal">domainSplit()</code> function returns an array of two values: the first value is the
subdomain; the second value is the highest registered domain.</p><p>The preview datafeed API returns the following results, which show that
"www.ml.elastic.co" has been split into "elastic.co" and "www.ml":</p><div class="pre_wrapper lang-js"><pre class="programlisting prettyprint lang-js">[
  {
    "@timestamp": 1490274000000,
    "clientip.keyword": "123.456.78.900",
    "hrd": "elastic.co",
    "sub": "www.ml"
  }
]</pre></div><p><a id="ml-configuring-transform9"></a><strong>Example 9: Transforming geo_point data. </strong>
</p><div class="pre_wrapper lang-console"><pre class="programlisting prettyprint lang-console">PUT _ml/anomaly_detectors/test4
{
  "analysis_config":{
    "bucket_span": "10m",
    "detectors":[
      {
        "function":"lat_long",
        "field_name": "my_coordinates"
      }
    ]
  },
  "data_description": {
  "time_field":"@timestamp",
  "time_format":"epoch_ms"
  }
}

PUT _ml/datafeeds/datafeed-test4
{
  "job_id": "test4",
  "indices": ["my_index"],
  "query": {
    "match_all": {
          "boost": 1
    }
  },
  "script_fields": {
    "my_coordinates": {
      "script": {
        "source": "doc['coords.lat'].value + ',' + doc['coords.lon'].value",
        "lang": "painless"
      }
    }
  }
}

GET _ml/datafeeds/datafeed-test4/_preview</pre></div><div class="console_widget" data-snippet="snippets/98.console"></div><p>
</p><p>In Elasticsearch, location data can be stored in <code class="literal">geo_point</code> fields but this data type is
not supported natively in machine learning analytics. This example of a script field
transforms the data into an appropriate format. For more information,
see <a class="xref" href="ml-functions.html#ml-geo-functions" title="Geographic functions">Geographic functions</a>.</p><p>The preview datafeed API returns the following results, which show that
<code class="literal">41.44</code> and <code class="literal">90.5</code> have been combined into "41.44,90.5":</p><div class="pre_wrapper lang-js"><pre class="programlisting prettyprint lang-js">[
  {
    "@timestamp": 1490274000000,
    "my_coordinates": "41.44,90.5"
  }
]</pre></div></div></div><div class="xpack section"><div class="titlepage"><div><div><h3 class="title"><a id="ml-delayed-data-detection"></a>Handling delayed data<a href="https://github.com/elastic/elasticsearch/edit/master/docs/reference/ml/anomaly-detection/delayed-data-detection.asciidoc" class="edit_me" title="Edit this page on GitHub" rel="nofollow">edit</a><a class="xpack_tag" href="/subscriptions"></a></h3></div></div></div><p>Delayed data are documents that are indexed late. That is to say, it is data
related to a time that the datafeed has already processed.</p><p>When you create a datafeed, you can specify a
<a class="ulink" href="https://www.elastic.co/guide/en/elasticsearch/reference/master/ml-datafeed-resource.html" target="_top"><code class="literal">query_delay</code></a> setting. This setting enables the
datafeed to wait for some time past real-time, which means any "late" data in
this period is fully indexed before the datafeed tries to gather it. However, if
the setting is set too low, the datafeed may query for data before it has been
indexed and consequently miss that document. Conversely, if it is set too high,
analysis drifts farther away from real-time. The balance that is struck depends
upon each use case and the environmental factors of the cluster.</p><div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="_why_worry_about_delayed_data"></a>Why worry about delayed data?<a href="https://github.com/elastic/elasticsearch/edit/master/docs/reference/ml/anomaly-detection/delayed-data-detection.asciidoc" class="edit_me" title="Edit this page on GitHub" rel="nofollow">edit</a></h4></div></div></div><p>This is a particularly prescient question. If data are delayed randomly (and
consequently are missing from analysis), the results of certain types of
functions are not really affected. In these situations, it all comes out okay in
the end as the delayed data is distributed randomly. An example would be a <code class="literal">mean</code>
metric for a field in a large collection of data. In this case, checking for
delayed data may not provide much benefit. If data are consistently delayed,
however, anomaly detection jobs with a <code class="literal">low_count</code> function may provide false positives.
In this situation, it would be useful to see if data comes in after an anomaly is
recorded so that you can determine a next course of action.</p></div><div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="_how_do_we_detect_delayed_data"></a>How do we detect delayed data?<a href="https://github.com/elastic/elasticsearch/edit/master/docs/reference/ml/anomaly-detection/delayed-data-detection.asciidoc" class="edit_me" title="Edit this page on GitHub" rel="nofollow">edit</a></h4></div></div></div><p>In addition to the <code class="literal">query_delay</code> field, there is a
<a class="ulink" href="https://www.elastic.co/guide/en/elasticsearch/reference/master/ml-datafeed-resource.html#ml-datafeed-delayed-data-check-config" target="_top">delayed data check config</a>,
which enables you to configure the datafeed to look in the past for delayed data.
Every 15 minutes or every <code class="literal">check_window</code>, whichever is smaller, the datafeed
triggers a document search over the configured indices. This search looks over a
time span with a length of <code class="literal">check_window</code> ending with the latest finalized bucket.
That time span is partitioned into buckets, whose length equals the bucket span
of the associated anomaly detection job. The <code class="literal">doc_count</code> of those buckets are then
compared with the job’s finalized analysis buckets to see whether any data has
arrived since the analysis. If there is indeed missing data due to their ingest
delay, the end user is notified. For example, you can see annotations in Kibana
for the periods where these delays occur.</p></div><div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="_what_to_do_about_delayed_data"></a>What to do about delayed data?<a href="https://github.com/elastic/elasticsearch/edit/master/docs/reference/ml/anomaly-detection/delayed-data-detection.asciidoc" class="edit_me" title="Edit this page on GitHub" rel="nofollow">edit</a></h4></div></div></div><p>The most common course of action is to simply to do nothing. For many functions
and situations, ignoring the data is acceptable. However, if the amount of
delayed data is too great or the situation calls for it, the next course of
action to consider is to increase the <code class="literal">query_delay</code> of the datafeed. This
increased delay allows more time for data to be indexed. If you have real-time
constraints, however, an increased delay might not be desirable. In which case,
you would have to <a class="ulink" href="https://www.elastic.co/guide/en/elasticsearch/reference/master/tune-for-indexing-speed.html" target="_top">tune for better indexing speed</a>.</p></div></div></div><div class="navfooter"><span class="prev"><a href="ml-configuration.html">
              « 
              Configuring anomaly detection</a>
           
        </span><span class="next">
           
          <a href="create-jobs.html">Creating anomaly detection jobs
               »
            </a></span></div>
                  <!-- end body -->
                </div>
                <div class="col-xs-12 col-sm-4 col-md-4" id="right_col">
                  <div id="rtpcontainer" style="display: block;">
                    <div class="mktg-promo">
                      <h3>Getting Started Videos</h3>
                      <ul class="icons">
                        <li class="icon-elasticsearch-white"><a href="https://www.elastic.co/webinars/getting-started-elasticsearch?baymax=default&elektra=docs&storm=top-video">Starting Elasticsearch</a></li>
                        <li class="icon-kibana-white"><a href="https://www.elastic.co/webinars/getting-started-kibana?baymax=default&elektra=docs&storm=top-video">Introduction to Kibana</a></li>
                        <li class="icon-logstash-white"><a href="https://www.elastic.co/webinars/getting-started-logstash?baymax=default&elektra=docs&storm=top-video">Logstash Starter Guide</a></li>
                      </ul>
                    </div>
                  </div>
                </div>
              </div>
            </div>
          </section>

        </div>


<div id='elastic-footer'></div>
<script src='https://www.elastic.co/elastic-footer.js'></script>
<!-- Footer Section end-->

      </section>
    </div>

<script type="text/javascript">
	var suggestionsUrl = "https://search.elastic.co/suggest";
	var localeUrl = '{"relative_url_prefix":"/","code":"en-us","display_code":"en-us","url":"/guide_template"}';
</script>
<script src="/static/js/swiftype_app_search.umd.min.js"></script>
<script type="text/javascript" src="/guide/static/docs.js"></script>
<script type="text/javascript">
  window.initial_state = {}</script>
  </body>
</html>
